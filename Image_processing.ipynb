{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZahB75R_hkO"
      },
      "source": [
        "# **Optical camera communications image processing for receiver**\n",
        "\n",
        "> Python script for the image processing part of the receiver of an optical camera comuunication system.\n",
        "\n",
        "> The objective is to demodulate a message, using on-off keying modulation/demodulation.\n",
        "\n",
        "> The python script will import an image and try to demodulate it by image processing methods.\n",
        "\n",
        "> The python script will be executed on a Raspberry pi 4 or a pc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K-MzrelAKRt"
      },
      "source": [
        "# **Necessary imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mB_DtiSc-YGO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uD9iPvKfARm4"
      },
      "source": [
        "# **The code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RhCdKvpPAW9C",
        "outputId": "f0f31464-b852-41f0-9b8e-e1621289f199"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 111\u001b[0m\n\u001b[0;32m    102\u001b[0m                     end \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[39m# just testing\u001b[39;00m\n\u001b[0;32m    108\u001b[0m         \u001b[39m# cv2.imshow('frame', bnwFrame)\u001b[39;00m\n\u001b[0;32m    109\u001b[0m          \n\u001b[0;32m    110\u001b[0m     \u001b[39m# Press Q on keyboard to exit\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m         \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    112\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m# Break the loop\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Logical variables for control\n",
        "start = 0 # start value must be 0\n",
        "end = 0 # start value must be 0\n",
        "\n",
        "# Lists for the transmited message\n",
        "start_list = []\n",
        "start_sequence = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
        "end_sequence = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
        "message_list = []\n",
        "N = len(start_sequence)\n",
        "\n",
        "# Start the video feed\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "if (cap.isOpened() == False):\n",
        "    print(\"Error opening video camera\")\n",
        "\n",
        "# Read until video is completed\n",
        "while(cap.isOpened()):\n",
        "     \n",
        "# Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "        \n",
        "        # If we received the message\n",
        "        if end == 1:\n",
        "            print(\"Message has been received! Getting message ready to be viewed.\")\n",
        "            break\n",
        "        \n",
        "        # Grayscale image and thresholding\n",
        "        grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        (thresh, bnwFrame) = cv2.threshold(grayframe, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # # Just for testing\n",
        "        # counting the number of pixels\n",
        "        # number_of_white_pix = np.sum(bnwFrame == 255)\n",
        "        # number_of_black_pix = np.sum(bnwFrame == 0)\n",
        "        # print('Number of white pixels:', number_of_white_pix)\n",
        "        # print('Number of black pixels:', number_of_black_pix)\n",
        "        # print(frame.shape)\n",
        "\n",
        "        # detection procedure and/or frame cropping\n",
        "\n",
        "        # Cropping: extract useful part of the frame (manually at first)\n",
        "        y_min = 60\n",
        "        y_max = 360\n",
        "        x_min = 360\n",
        "        x_max = 665\n",
        "        useful_frame = bnwFrame[y_min:y_max, x_min:x_max]\n",
        "        # # for testing\n",
        "        # cv2.imshow('frame', useful_frame)\n",
        "        # print(bnwFrame.shape)\n",
        "        # print(useful_frame.shape)\n",
        "\n",
        "        # # find the new image resolution\n",
        "        row_num = y_max - y_min # height\n",
        "        col_num = x_max - x_min # length\n",
        "\n",
        "\n",
        "        if start == 0:\n",
        "            # put the data of the frame inside the start_list\n",
        "            # for each row with step == thickness\n",
        "            thickness = 40 # pixels (change manually)\n",
        "            threshold = 40 # pixels (change manually)\n",
        "            for y in range(int(thickness/2), int(row_num - thickness/2), thickness):\n",
        "                row = useful_frame[y, 0:col_num-1] # get the row\n",
        "                holder = np.sum(row == 255) # add to holder the sum of white pixels\n",
        "                if holder > threshold:\n",
        "                    start_list.append(1)\n",
        "                else:\n",
        "                    start_list.append(0)\n",
        "            \n",
        "            # if list_size >= 30 check the last 30 elements\n",
        "            # if last 30 elements are the starting sequence start = 1\n",
        "            if len(start_list) >= N:\n",
        "                if start_list[-N:] == start_sequence:\n",
        "                    start = 1\n",
        "        elif start == 1:\n",
        "            # start storing the bits to the message list\n",
        "\n",
        "            # for each row with step == thickness\n",
        "            thickness = 10 # pixels (change manually)\n",
        "            threshold = 100 # pixels (change manually)\n",
        "            for y in range(int(thickness/2), int(row_num - thickness/2), thickness):\n",
        "                row = useful_frame[y, 0:col_num-1] # get the row\n",
        "                holder = np.sum(row == 255) # add to holder the sum of white pixels\n",
        "                if holder > threshold:\n",
        "                    message_list.append(1)\n",
        "                else:\n",
        "                    message_list.append(0)\n",
        "            \n",
        "            # plt.plot(new)\n",
        "            # plt.ylabel('Number of white pixels')\n",
        "            # plt.xlabel('Row number')\n",
        "            # plt.show()\n",
        "            # print(useful_frame.shape) # just testing\n",
        "            \n",
        "            # check for end sequence the last 30 bits\n",
        "            # if it's the end end = 1\n",
        "            if len(message_list) >= N:\n",
        "                if end_sequence == message_list[-N:]:\n",
        "                    end = 1\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        # just testing\n",
        "        # cv2.imshow('frame', bnwFrame)\n",
        "         \n",
        "    # Press Q on keyboard to exit\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        " \n",
        "# Break the loop\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# When everything done, release\n",
        "# the video capture object\n",
        "cap.release()\n",
        " \n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# extract the last 30 bits(the end sequence)\n",
        "n = len(end_sequence)\n",
        "\n",
        "# âœ… Remove the last N elements from a list (list slicing)\n",
        "final_message = message_list[:len(message_list) - n]\n",
        "# the message that was sent so that we can compare it to the received version\n",
        "message = np.zeros(1500)\n",
        "for i in range(message.size):\n",
        "  if (i % 2) == 0:\n",
        "    message[i] = 1\n",
        "errors = []\n",
        "if message == final_message:\n",
        "    print(\"Message received successfully\")\n",
        "else:\n",
        "    for i in range(len(final_message)):\n",
        "        if final_message[i] != message[i]:\n",
        "            errors.append(i)\n",
        "print(\"The errors are at the positions:\")\n",
        "print(errors)\n",
        "\n",
        "print(\"Total errors are:\")\n",
        "print(len(errors))\n",
        "\n",
        "print(\"Error percentage:\")\n",
        "print(len(errors)/len(message))\n",
        "\n",
        "# convert binary to jpg, png, mp3, raw, text...\n",
        "# show the received message"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Compare lists test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "equal\n",
            "[1, 1, 1, 1, 0]\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "start_sequence = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
        "temp = []\n",
        "for i in range(29):\n",
        "    temp.append(1)\n",
        "temp.append(0)\n",
        "N = 5\n",
        "\n",
        "if start_sequence == temp:\n",
        "    print(\"equal\")\n",
        "elif start_sequence != temp:\n",
        "    print(\"not equal\")\n",
        "a = start_sequence[-N:]\n",
        "print(a)\n",
        "print(len(start_sequence))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Sub-sampling test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture('output.mp4')\n",
        "\n",
        "y_min = 60\n",
        "y_max = 360\n",
        "x_min = 360\n",
        "x_max = 665\n",
        "frame_width = x_max - x_min\n",
        "frame_height = y_max - y_min\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('draw_lines.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    print(\"ok\")\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret:\n",
        "        print(\"ok\")\n",
        "        # for each row with step == thickness\n",
        "        thickness = 10 # pixels (change manually)\n",
        "        threshold = 100 # pixels (change manually)\n",
        "        for y in range(int(thickness/2), int(frame_height - thickness/2), thickness):\n",
        "            cv2.line(frame, (y, 0), (y, frame.shape[0]), (0, 0, 255), 5)\n",
        "\n",
        "        # Write the modified frame to the output video file\n",
        "        out.write(frame)\n",
        "\n",
        "        # Display the frame\n",
        "        cv2.imshow('frame', frame)\n",
        "        \n",
        "        # Exit if 'q' is pressed\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release the resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "de47f5c92c0ee6f12a59a5613ac5feff6aab19ddff207ba0b3964cced08c4ccc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
